{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Named Entity Recognition with MIT Restaurant Dataset\n",
        "\n",
        "Your name: Ha Trung Tin\n",
        "\n",
        "Student ID: BI11-261\n",
        "\n",
        "**Due: 23:59 19/3/2023**\n",
        "\n",
        "## Task Description\n",
        "\n",
        "In this assignment, you will train a NER Model using Conditional Random Fields (CRF) on and report the accuracy of your model on the test dataset.\n",
        "\n",
        "You will use the [MIT Restaurant Dataset](https://groups.csail.mit.edu/sls/downloads/restaurant/) dataset to do the task.\n",
        "\n",
        "## How to submit\n",
        "\n",
        "- Attach notebook file (.ipynb) and submit your work to Google Class Room \n",
        "- Name your file as YourName_StudentID_Assignment4.ibynb. E.g., Nguyen_Van_A_ST099834_Assignment4.ipynb\n",
        "- Write your name and student ID into this notebook\n",
        "- Copying others' assignments is strictly prohibited.\n"
      ],
      "metadata": {
        "id": "PGcNXgEH9S3s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install python-crfsuite"
      ],
      "metadata": {
        "id": "7-wE5Ygy_851"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q python-crfsuite"
      ],
      "metadata": {
        "id": "qhjb-9J2AAMu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17839a71-5e88-40eb-9c1f-f3a83907db24"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m0.8/1.0 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "26ieJ1aEAQs-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import chain\n",
        "import pycrfsuite"
      ],
      "metadata": {
        "id": "yGewX5VmASAU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "We will use [MIT Restaurant Dataset](https://groups.csail.mit.edu/sls/downloads/restaurant/) dataset.\n",
        "\n",
        "The data set is already in CoNLL format. We will use the [train](https://groups.csail.mit.edu/sls/downloads/restaurant/restauranttrain.bio) data to create the NER model and evaluate the model on the [test](https://groups.csail.mit.edu/sls/downloads/restaurant/restauranttest.bio) data."
      ],
      "metadata": {
        "id": "Ie-POGzEv8xA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download data"
      ],
      "metadata": {
        "id": "2U0ME8SbxIS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!rm -f restauranttrain.bio\n",
        "!rm -f restauranttest.bio\n",
        "\n",
        "!wget https://groups.csail.mit.edu/sls/downloads/restaurant/restauranttest.bio\n",
        "!wget https://groups.csail.mit.edu/sls/downloads/restaurant/restauranttrain.bio"
      ],
      "metadata": {
        "id": "PcFJBAy7xa-x"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading data (30 points)\n",
        "\n",
        "In this part, you will load a data file into a list of sentences. Each sentence is a list of (word, tag) tuples.\n",
        "\n",
        "**Note: Blank lines are used to seperate sentences.**\n",
        "\n",
        "For instance, the sentence below will be loaded into a list\n",
        "\n",
        "```\n",
        "O\ta\n",
        "B-Rating\tfour\n",
        "I-Rating\tstar\n",
        "O\trestaurant\n",
        "B-Location\twith\n",
        "I-Location\ta\n",
        "B-Amenity\tbar\n",
        "```\n",
        "\n",
        "You will complete the function below"
      ],
      "metadata": {
        "id": "MLyiSFarytjC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Add necessary import here\n",
        "def load_data(file_path):\n",
        "    \"\"\"Load data into a list of list of (word, tag) tuples\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to data\n",
        "\n",
        "    Returns:\n",
        "        sentences: list of (word, tag) tuples\n",
        "    \"\"\"\n",
        "    sentences = []\n",
        "    \n",
        "    #TODO: Write your code here\n",
        "    with open(file_path, \"r\") as f:\n",
        "        sentence = []\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line:\n",
        "                tag, word = line.split('\\t')\n",
        "                sentence.append((word, tag))\n",
        "            else:\n",
        "                if sentence:\n",
        "                    sentences.append(sentence)\n",
        "                    sentence = []\n",
        "\n",
        "        if sentence:\n",
        "            sentences.append(sentence)\n",
        "\n",
        "    return sentences"
      ],
      "metadata": {
        "id": "M6UmjUBP06c4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sents = load_data('restauranttrain.bio')\n",
        "test_sents = load_data('restauranttest.bio')"
      ],
      "metadata": {
        "id": "zy6fIDnF19nC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check the number of sentences in train and test data"
      ],
      "metadata": {
        "id": "oOzFyaKo2Wgl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_sents)"
      ],
      "metadata": {
        "id": "jVdNqwKH2mi8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7319d4e5-5158-4f4f-f07e-c66fdb9229fb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7660"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_sents)"
      ],
      "metadata": {
        "id": "sVVcSv6r2oq6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72bb01d5-808e-40df-870a-3aaa4b8e2dc4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1521"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sents[0]"
      ],
      "metadata": {
        "id": "Msy21RWM232U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6488ccde-719f-4ce1-dfda-740784c20698"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('2', 'B-Rating'),\n",
              " ('start', 'I-Rating'),\n",
              " ('restaurants', 'O'),\n",
              " ('with', 'O'),\n",
              " ('inside', 'B-Amenity'),\n",
              " ('dining', 'I-Amenity')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Features (50 points)\n",
        "\n",
        "We can extract as many features as you want. You will implement following basic features.\n",
        "\n",
        "※ Of course, you can add more features.\n",
        "\n",
        "*Word identity (lowercase)*\n",
        "\n",
        "- Previous word identity\n",
        "- Current word identity\n",
        "- Next word\n",
        "- Previous word and current word combination. Concat the previous word the current word by '||'\n",
        "- Current word and next word combination. Concat two words by '||'\n",
        "\n",
        "*Word shapes*\n",
        "\n",
        "- Word prefix and suffix (4 characters)\n",
        "- The first character of the current word is the capital letter\n",
        "\n",
        "**All you need to do is to complete the function `word2feature`.**"
      ],
      "metadata": {
        "id": "FVv2iYez3CBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word2features(sentence, i):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "        sentence (list): list of words [w1, w2,...,w_n]\n",
        "        i (int): index of the word\n",
        "    Return:\n",
        "        features (dict): dictionary of features\n",
        "    \"\"\"\n",
        "    word = sentence[i]\n",
        "    prev_word = '' if i==0 else sentence[i-1].lower()\n",
        "    next_word = '' if i==len(sentence)-1 else sentence[i+1].lower()\n",
        "    features = {\n",
        "        #TODO: Write your features here\n",
        "        'word.lower()': word.lower(),\n",
        "        'prev_word.lower()': prev_word.lower(),\n",
        "        'next_word.lower()': next_word.lower(),\n",
        "        'prev_word||word.lower()': f'{prev_word.lower()}||{word.lower()}',\n",
        "        'word.lower()||next_word.lower()': f'{word.lower()}||{next_word.lower()}',\n",
        "        'word_prefix': word[:4],\n",
        "        'word_suffix': word[-4:],\n",
        "        'is_capitalized': word[0].isupper(),\n",
        "    }\n",
        "    \n",
        "    return features\n",
        "\n",
        "\n",
        "def sent2features(sentence):\n",
        "    \"\"\"\n",
        "    sentence is a list of words [w1, w2,...,w_n]\n",
        "    \"\"\"\n",
        "    return [word2features(sentence, i) for i in range(len(sentence))]\n",
        "\n",
        "\n",
        "def sent2labels(sentence):\n",
        "    \"\"\"\n",
        "    sentence is a list of tuples (word, postag)\n",
        "    \"\"\"    \n",
        "    return [tag for token, tag in sentence]\n",
        "\n",
        "def untag(sentence):\n",
        "    \"\"\"\n",
        "    sentence is a list of tuples (word, postag)\n",
        "    \"\"\"\n",
        "    return [token for token, _ in sentence]"
      ],
      "metadata": {
        "id": "yfBAsejb5iir"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try to extract features for the first sentence"
      ],
      "metadata": {
        "id": "t7fSWZJQ83Vx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sents[0]"
      ],
      "metadata": {
        "id": "iNrn8zBrS-Sa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9e2db71-3ab1-4b96-8e7e-15a4978dba2e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('2', 'B-Rating'),\n",
              " ('start', 'I-Rating'),\n",
              " ('restaurants', 'O'),\n",
              " ('with', 'O'),\n",
              " ('inside', 'B-Amenity'),\n",
              " ('dining', 'I-Amenity')]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent2features(untag(train_sents[0]))[0]"
      ],
      "metadata": {
        "id": "KFTpTYO68tfD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f058f6a-32e1-4460-e01a-3836de3143f5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'word.lower()': '2',\n",
              " 'prev_word.lower()': '',\n",
              " 'next_word.lower()': 'start',\n",
              " 'prev_word||word.lower()': '||2',\n",
              " 'word.lower()||next_word.lower()': '2||start',\n",
              " 'word_prefix': '2',\n",
              " 'word_suffix': '2',\n",
              " 'is_capitalized': False}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create train/test data"
      ],
      "metadata": {
        "id": "9Xl5Tyd4-zZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = [sent2features(untag(s)) for s in train_sents]\n",
        "y_train = [sent2labels(s) for s in train_sents]\n",
        "\n",
        "X_test = [sent2features(untag(s)) for s in test_sents]\n",
        "y_test = [sent2labels(s) for s in test_sents]"
      ],
      "metadata": {
        "id": "nKUVYzMQ-3ef"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "La08Oyam_ZjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "trainer = pycrfsuite.Trainer(verbose=False)\n",
        "\n",
        "for xseq, yseq in zip(X_train, y_train):\n",
        "    trainer.append(xseq, yseq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-C-fq8x_brV",
        "outputId": "20c33757-6418-4ca9-ff03-9ab9d12832bf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 683 ms, sys: 22.2 ms, total: 705 ms\n",
            "Wall time: 708 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Set model parameters\n",
        "\n",
        "max_iterations = 50 #@param[50, 20, 100]\n",
        "\n",
        "trainer.set_params({\n",
        "    'c1': 1.0,   # coefficient for L1 penalty\n",
        "    'c2': 1e-3,  # coefficient for L2 penalty\n",
        "    'max_iterations': max_iterations,\n",
        "\n",
        "    # include transitions that are possible, but not observed\n",
        "    'feature.possible_transitions': True\n",
        "})"
      ],
      "metadata": {
        "id": "C0XJtpOtO2Pl"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "trainer.train('mitrestaurant.crfsuite')"
      ],
      "metadata": {
        "id": "v5VXTKZdO4aU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9c28952-5b8a-435a-fa7d-4ce976890be5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 7.31 s, sys: 38 ms, total: 7.35 s\n",
            "Wall time: 7.4 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation (20 points)\n",
        "\n",
        "We will use [seqeval](https://github.com/chakki-works/seqeval) package for evaluation NER result."
      ],
      "metadata": {
        "id": "wQQLY7m-PPmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q seqeval[cpu]"
      ],
      "metadata": {
        "id": "GtpO8Mb4dFMg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18c48c9d-912b-4971-f3f4-a5317be226a7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 KB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make Predictions"
      ],
      "metadata": {
        "id": "6UCqdlNvPWZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tagger = pycrfsuite.Tagger()\n",
        "tagger.open('mitrestaurant.crfsuite')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVenrYzcPYoM",
        "outputId": "bbfb4417-83a8-4854-8863-a565bc75a97c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<contextlib.closing at 0x7fc4c2d23700>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_sent = test_sents[0]\n",
        "example_sent"
      ],
      "metadata": {
        "id": "rAfV8QhcPb9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd19fdf1-bc3e-4fa3-9965-bbcec20efbd3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('a', 'O'),\n",
              " ('four', 'B-Rating'),\n",
              " ('star', 'I-Rating'),\n",
              " ('restaurant', 'O'),\n",
              " ('with', 'B-Location'),\n",
              " ('a', 'I-Location'),\n",
              " ('bar', 'B-Amenity')]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Predicted:\", ' '.join(tagger.tag(sent2features(untag(example_sent)))))\n",
        "print(\"Correct:  \", ' '.join(sent2labels(example_sent)))"
      ],
      "metadata": {
        "id": "8hGrDn-4P55R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c69c6ab7-1e89-4df7-d102-f96268de8c43"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: O B-Rating I-Rating O O O B-Amenity\n",
            "Correct:   O B-Rating I-Rating O B-Location I-Location B-Amenity\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "y_pred = [tagger.tag(xseq) for xseq in X_test]"
      ],
      "metadata": {
        "id": "3ee18ZKIQqgU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f5c5b82-9a56-4d4c-9bf4-aa1409eff987"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 84.5 ms, sys: 4.03 ms, total: 88.6 ms\n",
            "Wall time: 89 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from seqeval.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "Ns2UeFU5U96O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "903876d5-ecb6-44d1-fb90-f7b624400db7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        Amenity       0.71      0.65      0.68       533\n",
            "        Cuisine       0.84      0.81      0.83       532\n",
            "           Dish       0.78      0.72      0.75       288\n",
            "          Hours       0.73      0.65      0.69       212\n",
            "       Location       0.82      0.80      0.81       812\n",
            "          Price       0.80      0.81      0.80       171\n",
            "         Rating       0.79      0.77      0.78       201\n",
            "Restaurant_Name       0.78      0.75      0.77       402\n",
            "\n",
            "      micro avg       0.79      0.75      0.77      3151\n",
            "      macro avg       0.78      0.75      0.76      3151\n",
            "   weighted avg       0.79      0.75      0.77      3151\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "1. Datasets for Entity Recognition: https://github.com/juand-r/entity-recognition-datasets\n",
        "2. [sklearn-crfsuite tutorial](https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html#let-s-use-conll-2002-data-to-build-a-ner-system). \n",
        "3. [Quick Recipe: Build a POS tagger using a Conditional Random Field](https://nlpforhackers.io/crf-pos-tagger/)\n",
        "4. [NLP Guide: Identifying Part of Speech Tags using Conditional Random Fields](https://medium.com/analytics-vidhya/pos-tagging-using-conditional-random-fields-92077e5eaa31)\n",
        "5. [CRFsuite - Tutorial on Chunking Task](http://www.chokkan.org/software/crfsuite/tutorial.html)"
      ],
      "metadata": {
        "id": "oRMhFCCEBhds"
      }
    }
  ]
}